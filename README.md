# 中文医疗 RAG 问答系统 (Chinese Medical RAG System)

## 1. 项目概述
本项目构建了一个基于 **RAG（检索增强生成）** 技术的中文医疗问答系统。针对通用大模型在医疗领域知识匮乏、易产生幻觉的问题，本系统结合了专业的医疗知识库 (**cMedQA2**) 和大语言模型 (**Qwen3-1.7B**)，旨在提供准确、可信且响应迅速的医疗健康咨询服务。

系统后端采用 **vLLM** 进行高性能推理，前端通过 **Gradio** 实现了支持多轮对话、长上下文处理、引用溯源及拒答机制的实时交互界面。

## 2. 数据来源与处理
### 2.1 数据来源
本项目使用 **[cMedQA2](https://github.com/zhangyics/CMedQA2)** 中文医疗问答数据集。该数据集包含超过 10 万条真实的医患问答对，涵盖了多种疾病、症状和治疗方案，是构建医疗领域问答系统的理想数据源。

### 2.2 数据处理流程
1.  **数据清洗**: 去除原始数据中的无效字符、HTML 标签及重复条目，确保数据质量。
2.  **文本分块 (Chunking)**: 
    *   使用自定义的中文文本切分器 (`ChineseTextSplitter`)。
    *   **策略**: 将长文档切分为 **1024 tokens** 的片段，设置 **64 tokens** 的重叠 (overlap)，以防止切分点丢失关键语义信息。
3.  **向量化 (Embedding)**: 
    *   模型: 使用 `bge-base-zh-v1.5` 模型将文本片段转换为高维向量。
    *   该模型在中文语义检索任务上表现优异，能够有效捕捉医疗文本的语义特征。
4.  **向量数据库构建**: 
    *   使用 **FAISS** (Facebook AI Similarity Search) 构建索引。
    *   索引类型: `IndexFlatL2` (欧氏距离)，支持高效的精确相似度检索。

## 3. 方法
### 3.1 系统架构
系统主要由三个模块组成：
1.  **检索模块 (Retriever)**: 基于 FAISS 向量库，根据用户问题检索 Top-K 个最相关的医疗文档片段。
2.  **生成模块 (Generator)**: 基于 Qwen3-1.7B 模型，利用检索到的上下文生成回答。
3.  **交互模块 (Interface)**: 处理用户输入，管理对话历史，并展示最终结果。

### 3.2 关键技术
*   **检索策略**: 
    *   支持动态调整 `top_k` (默认 5)。
    *   引入相似度阈值 (`score_threshold`) 过滤低相关性文档，减少噪声干扰。
*   **Prompt Engineering**: 
    *   设计了专门的 **System Prompt**，规范模型的角色设定（专业医疗助手）。
    *   在 Prompt 中明确要求模型基于检索内容回答，并标注引用来源。
    *   **拒答机制**: 当检索内容不足以回答问题时，指示模型明确告知用户，避免强行回答导致幻觉。
*   **高性能推理**: 
    *   使用 **vLLM** 部署 Qwen 模型，利用 PagedAttention 技术显著提升推理吞吐量和响应速度。

## 4. 实验结果
我们使用 `scripts/evaluate.py` 对系统进行了自动化评估，主要关注检索准确率和生成质量。

### 4.1 评估指标
*   **Hit Rate (HR)**: 检索到的 Top-K 文档中是否包含正确答案的相关信息。
*   **Accuracy**: 模型生成的回答与标准答案的语义一致性（基于关键词匹配或语义相似度）。

### 4.2 结果展示 (示例)
*(注：以下数据为基于部分测试集的评估结果示例)*

| Metric | Top-1 | Top-3 | Top-5 |
| :--- | :---: | :---: | :---: |
| **Retrieval Hit Rate** | 45.2% | 68.5% | 78.3% |
| **Generation Accuracy** | - | - | 62.1% |


## 5. 问题分析与创新点
### 5.1 主要成果和创新点
1.  **全流程 RAG 系统实现**: 构建了从数据清洗、分块、向量化到向量库构建的完整数据链路，并成功集成 LLM 实现问答。
2.  **高性能推理与交互**: 后端采用 vLLM 确保高并发下的低延迟，前端 Gradio 界面支持流式输出，用户体验流畅。
3.  **增强的可信度**: 
    *   **引用溯源**: 每一条回答都附带参考文档来源，用户可验证信息的真实性。
    *   **拒答机制**: 有效抑制了模型在知识盲区时的幻觉问题。
4.  **模块化评估体系**: 内置了自动化评估脚本，支持定量分析系统性能，便于后续优化。

### 5.2 问题分析
*   **检索精度**: 简单的向量相似度检索在处理复杂语义匹配时仍有局限，可能导致召回不准确。
*   **长尾知识**: 对于数据集中未覆盖的罕见病症，系统无法回答。

## 6. Demo
### 启动方式
```bash
# 1. 启动 vLLM 服务
bash scripts/start_vllm.sh

# 2. 启动 Web Demo
python app.py
```

## 7. 未来改进方向
1.  **引入 Rerank 机制**: 在检索后加入重排序模型 (如 bge-reranker)，进一步提升 Top-K 文档的相关性。
2.  **模型微调 (SFT/LoRA)**: 在特定医疗数据上对 Qwen 模型进行微调，使其更适应医疗领域的语言风格和知识结构。
3.  **知识图谱结合**: 引入医疗知识图谱，增强系统对实体关系（如 药品-疾病-症状）的理解能力，实现更复杂的推理问答。
4.  **混合检索**: 结合关键词检索 (BM25) 和向量检索，提升对专有名词的检索效果。
